{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 21:51:10.549426: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import scripts\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'scripts' from '/Users/alfred/Documents/chinese_mnist_analysis/scripts.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(scripts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Chinese MNIST using Transfer Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CLASSES = 15\n",
    "IMAGE_SIZE = (64, 64)\n",
    "IMAGE_SHAPE = IMAGE_SIZE + (3,)\n",
    "\n",
    "CLASSIFIER_LEARNING_RATE = 0.0001\n",
    "CLASSFIER_NUMBER_OF_EPOCHS = 1\n",
    "BATCH_SIZE = 1\n",
    "OPTIMIZER = tf.keras.optimizers.Adam\n",
    "LOSS_MEASURE = tf.keras.losses.SparseCategoricalCrossentropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 files belonging to 15 classes.\n",
      "Found 15 files belonging to 15 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 21:51:20.670659: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "debug_dataloader = tf.keras.utils.image_dataset_from_directory(\"./debug_dataset/\",\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               image_size=IMAGE_SIZE,\n",
    "                                                               seed=413)\n",
    "validation_dataloader = tf.keras.utils.image_dataset_from_directory(\"./debug_dataset/\",\n",
    "                                                               batch_size=BATCH_SIZE,\n",
    "                                                               image_size=IMAGE_SIZE,\n",
    "                                                               seed=413)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a Peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripts.peek_into_dataloader(debug_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache and Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_dataloader = debug_dataloader.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_dataloader = validation_dataloader.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_efficientnet_base_model = tf.keras.applications.EfficientNetV2S(include_top=False, input_shape=IMAGE_SHAPE) # expects an input to be in the range [0, 255].\n",
    "medium_efficientnet_base_model = tf.keras.applications.EfficientNetV2M(include_top=False, input_shape=IMAGE_SHAPE)\n",
    "large_efficientnet_base_model = tf.keras.applications.EfficientNetV2L(include_top=False, input_shape=IMAGE_SHAPE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_efficientnet = scripts.add_classifier(small_efficientnet_base_model, IMAGE_SHAPE, NUMBER_OF_CLASSES)\n",
    "medium_efficientnet = scripts.add_classifier(medium_efficientnet_base_model, IMAGE_SHAPE, NUMBER_OF_CLASSES)\n",
    "large_efficientnet = scripts.add_classifier(large_efficientnet_base_model, IMAGE_SHAPE, NUMBER_OF_CLASSES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the small efficientnet base model: 513\n",
      "Number of layers in the medium efficientnet base model: 740\n",
      "Number of layers in the large efficientnet base model: 1028\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of layers in the small efficientnet base model: {}\".format(len(small_efficientnet.layers[1].layers)))\n",
    "print(\"Number of layers in the medium efficientnet base model: {}\".format(len(medium_efficientnet.layers[1].layers)))\n",
    "print(\"Number of layers in the large efficientnet base model: {}\".format(len(large_efficientnet.layers[1].layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-s (Functiona  (None, 2, 2, 1280)       20331360  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              5243904   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                15375     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,590,639\n",
      "Trainable params: 25,436,767\n",
      "Non-trainable params: 153,872\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "small_efficientnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-m (Functiona  (None, 2, 2, 1280)       53150388  \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1024)              5243904   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                15375     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,409,667\n",
      "Trainable params: 58,117,635\n",
      "Non-trainable params: 292,032\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "medium_efficientnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " efficientnetv2-l (Functiona  (None, 2, 2, 1280)       117746848 \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 5120)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1024)              5243904   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 15)                15375     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,006,127\n",
      "Trainable params: 122,493,551\n",
      "Non-trainable params: 512,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "large_efficientnet.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_NAMES = np.array([[\"small_efficientnet_with_debug_dataset\"],\n",
    "                             [\"medium_efficientnet_with_debug_dataset\"],\n",
    "                             [\"large_efficientnet_with_debug_dataset\"]])\n",
    "MODELS = [small_efficientnet, medium_efficientnet, large_efficientnet]\n",
    "OPTIMIZERS = [OPTIMIZER, OPTIMIZER, OPTIMIZER]\n",
    "DATALOADERS = [debug_dataloader]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Classifier\n",
    "Train the classifier of each of the three models using the medium dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 69s 924ms/step - loss: 3.2562 - accuracy: 0.0000e+00 - val_loss: 2.0726 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "accuracies_after_training_classifiers = scripts.train_classifiers(MODELS,\n",
    "                                                                  OPTIMIZERS,\n",
    "                                                                  DATALOADERS,\n",
    "                                                                  validation_dataloader,\n",
    "                                                                  CLASSIFIER_LEARNING_RATE,\n",
    "                                                                  LOSS_MEASURE(from_logits=True),\n",
    "                                                                  CLASSFIER_NUMBER_OF_EPOCHS,\n",
    "                                                                  CHECKPOINT_NAMES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "Only fine tune after the classifer have been trained."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNING_LEARNING_RATE = CLASSIFIER_LEARNING_RATE / 10\n",
    "FINE_TUNING_NUMBER_OF_EPOCHS = 1\n",
    "PERCENTAGE_OF_LAYERS_TO_FREEZE = [0.2, 0.4, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts.fine_tune(OPTIMIZERS,\n",
    "                  DATALOADERS,\n",
    "                  validation_dataloader,\n",
    "                  FINE_TUNING_LEARNING_RATE,\n",
    "                  LOSS_MEASURE(from_logits=True),\n",
    "                  FINE_TUNING_NUMBER_OF_EPOCHS,\n",
    "                  CHECKPOINT_NAMES,\n",
    "                  PERCENTAGE_OF_LAYERS_TO_FREEZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc413",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
